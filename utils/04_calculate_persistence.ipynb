{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9f80eb5e-490f-4045-9a6a-33cdc486e3b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# MAGIC %md\n",
    "# MAGIC # Calcular persistencia de incidencias\n",
    "# MAGIC \n",
    "# MAGIC \n",
    "# MAGIC **L��gica:**\n",
    "# MAGIC 1.  `main()` orquesta todo el proceso.\n",
    "# MAGIC 2.  Busca ejecuciones en `dq_validations_traceability` que necesiten c��lculo de persistencia.\n",
    "# MAGIC 3.  Encuentra los pares de ejecuci��n (N vs N-1) usando `dq_execution_traceability`.\n",
    "# MAGIC 4.  Carga las evidencias (`dq_evidences`), filtrando por las particiones de fecha (N y N-1).\n",
    "# MAGIC 5.  Calcula las m��tricas de fallos nuevos, persistentes y resueltos.\n",
    "# MAGIC 6.  Actualiza (`MERGE`) la tabla `dq_validations_traceability` con estas m��tricas.\n",
    "# MAGIC 7.  Limpia los nulos restantes (ej: primeras ejecuciones) y los establece en 0.\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# DBTITLE 1, 1. Imports y constantes\n",
    "from pyspark.sql.functions import col, lag, desc, row_number, count, when, lit, coalesce\n",
    "from pyspark.sql.window import Window\n",
    "from delta.tables import DeltaTable\n",
    "import sys\n",
    "\n",
    "# --- Widgets ---\n",
    "#dbutils.widgets.text(\"table_id\", \"\", \"Id de la tabla a validar\")\n",
    "dbutils.widgets.text(\"table_name\", \"maestro_demo\", \"Id de la tabla a validar\")\n",
    "dbutils.widgets.text(\"catalog_name\", \"workspace\", \"Catálogo de UC donde residen las tablas\")\n",
    "dbutils.widgets.text(\"schema_name\", \"dq_framework\", \"Esquema de UC donde residen las tablas\")\n",
    "# COMMAND ----------\n",
    "\n",
    "# DBTITLE 2, 2. Carga de librerías y definición de constantes/mapas\n",
    "\n",
    "CATALOG = dbutils.widgets.get(\"catalog_name\")\n",
    "SCHEMA = dbutils.widgets.get(\"schema_name\")\n",
    "\n",
    "EXECUTION_TABLE = f\"{CATALOG}.{SCHEMA}.dq_execution_traceability\"\n",
    "VALIDATIONS_TABLE = f\"{CATALOG}.{SCHEMA}.dq_validations_traceability\"\n",
    "EVIDENCES_TABLE = f\"{CATALOG}.{SCHEMA}.dq_evidences\"\n",
    "\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# DBTITLE 2, 2. Funci��n Principal (main)\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Flujo principal de orquestaci��n para el c��lculo de persistencia\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # --- 1. Encontrar ejecuciones para procesar ---\n",
    "        \n",
    "        df_validations_to_process = (\n",
    "            spark.table(VALIDATIONS_TABLE)\n",
    "            .filter(col(\"status\").isin(\"PASSED\", \"FAILED\") & col(\"persistent_failures\").isNull())\n",
    "            .select(\"execution_id\", \"validation_id\", \"rule_id\")\n",
    "            .distinct()\n",
    "        )\n",
    "\n",
    "        df_executions_to_process = df_validations_to_process.select(\"execution_id\").distinct()\n",
    "\n",
    "        if df_executions_to_process.isEmpty():\n",
    "            print(\"No se encontraron ejecuciones nuevas para procesar.\")\n",
    "            return \"��xito: No hay nuevas ejecuciones para procesar.\"\n",
    "\n",
    "        print(f\"Se encontraron {df_executions_to_process.count()} ejecuciones para procesar.\")\n",
    "\n",
    "        # --- 2. Encontrar pares de Ejecuci��n (N vs N-1) ---\n",
    "        window_prev_exec = Window.partitionBy(\"table_id\").orderBy(col(\"execution_timestamp\"))\n",
    "\n",
    "        df_execution_pairs = (\n",
    "            spark.table(EXECUTION_TABLE)\n",
    "            .filter(col(\"status\") == \"SUCCESS\") # Comparar solo contra ejecuciones anteriores exitosas\n",
    "            .withColumn(\"prev_execution_id\", lag(\"execution_id\", 1).over(window_prev_exec))\n",
    "            .withColumn(\"prev_execution_date\", lag(\"execution_timestamp\", 1).over(window_prev_exec))\n",
    "            .join(df_executions_to_process, \"execution_id\")\n",
    "            .select(\n",
    "                col(\"execution_id\").alias(\"current_execution_id\"),\n",
    "                col(\"execution_date\").alias(\"current_execution_date\"),\n",
    "                col(\"prev_execution_id\"),\n",
    "                col(\"prev_execution_date\"),\n",
    "                \"table_id\"\n",
    "            )\n",
    "            .filter(col(\"prev_execution_id\").isNotNull())\n",
    "        )\n",
    "\n",
    "        if df_execution_pairs.isEmpty():\n",
    "            print(\"Ejecuciones nuevas encontradas, pero no tienen una ejecuci��n anterior v��lida para comparar.\")\n",
    "        else:\n",
    "            print(\"Pares de ejecuci��n N y N-1 encontrados:\")\n",
    "\n",
    "        # --- 3. Cargar evidencias relevantes (Usando particiones) ---\n",
    "        # Selecciona solo las columnas de fechas relevantes\n",
    "\n",
    "        dates_df = df_execution_pairs.select(\n",
    "            col(\"current_execution_date\").alias(\"execution_date\")\n",
    "        ).union(\n",
    "            df_execution_pairs.select(col(\"prev_execution_date\").alias(\"execution_date\"))\n",
    "        ).distinct()\n",
    "\n",
    "        all_relevant_dates = [row.execution_date for row in dates_df.collect()]\n",
    "\n",
    "        if not all_relevant_dates:\n",
    "             print(\"No hay pares de ejecuci��n para cargar evidencias\")\n",
    "             df_evidences = spark.createDataFrame([], schema=spark.table(EVIDENCES_TABLE).schema)\n",
    "        else:\n",
    "            print(f\"Cargando evidencias para {len(all_relevant_dates)} particiones de fecha...\")\n",
    "            df_evidences = (\n",
    "                spark.table(EVIDENCES_TABLE)\n",
    "                .filter(col(\"execution_date\").isin(all_relevant_dates))\n",
    "                .select(\"execution_id\", \"validation_id\", \"table_pk\")\n",
    "                .distinct()\n",
    "                #.cache()\n",
    "            )\n",
    "            print(f\"Evidencias cargadas: {df_evidences.count()} registros.\")\n",
    "\n",
    "        # --- 4. Calcular m��tricas de persistencia ---\n",
    "        '''\n",
    "        print(\"Calculando m��tricas de persistencia (New, Persistent, Resolved)...\")\n",
    "\n",
    "        execution_ids_n = [row.current_execution_id for row in df_execution_pairs.collect()]\n",
    "        execution_ids_n_minus_1 = [row.prev_execution_id for row in df_execution_pairs.collect()]\n",
    "\n",
    "        df_current_failures = df_evidences.filter(col(\"execution_id\").isin(execution_ids_n))\n",
    "        df_previous_failures = df_evidences.filter(col(\"execution_id\").isin(execution_ids_n_minus_1)) \\\n",
    "                                         .withColumnRenamed(\"execution_id\", \"prev_execution_id\")\n",
    "\n",
    "        df_previous_failures_mapped = (df_previous_failures\n",
    "            .join(df_execution_pairs.select(\"prev_execution_id\", \"current_execution_id\"), \"prev_execution_id\")\n",
    "            .select(col(\"current_execution_id\").alias(\"execution_id\"), \"validation_id\", \"table_pk\")\n",
    "        )\n",
    "\n",
    "        df_new = (\n",
    "            df_current_failures.join(df_previous_failures_mapped, [\"execution_id\", \"validation_id\", \"table_pk\"], \"left_anti\")\n",
    "            .groupBy(\"execution_id\", \"validation_id\").agg(count(\"*\").alias(\"new_failures\"))\n",
    "        )\n",
    "        df_persistent = (\n",
    "            df_current_failures.join(df_previous_failures_mapped, [\"execution_id\", \"validation_id\", \"table_pk\"], \"inner\")\n",
    "            .groupBy(\"execution_id\", \"validation_id\").agg(count(\"*\").alias(\"persistent_failures\"))\n",
    "        )\n",
    "        df_resolved = (\n",
    "            df_previous_failures_mapped.join(df_current_failures, [\"execution_id\", \"validation_id\", \"table_pk\"], \"left_anti\")\n",
    "            .groupBy(\"execution_id\", \"validation_id\").agg(count(\"*\").alias(\"resolved_failures\"))\n",
    "        )\n",
    "\n",
    "        df_metrics = (\n",
    "            df_validations_to_process\n",
    "            .join(df_new, [\"execution_id\", \"validation_id\"], \"left\")\n",
    "            .join(df_persistent, [\"execution_id\", \"validation_id\"], \"left\")\n",
    "            .join(df_resolved, [\"execution_id\", \"validation_id\"], \"left\")\n",
    "            .select(\n",
    "                \"execution_id\",\n",
    "                \"validation_id\",\n",
    "                coalesce(col(\"new_failures\"), lit(0)).alias(\"new_failures\"),\n",
    "                coalesce(col(\"persistent_failures\"), lit(0)).alias(\"persistent_failures\"),\n",
    "                coalesce(col(\"resolved_failures\"), lit(0)).alias(\"resolved_failures\")\n",
    "            )\n",
    "        )\n",
    "        print(\"C��lculo de m��tricas finalizado.\")\n",
    "        '''\n",
    "\n",
    "        # --- 1. Crear ventana sobre cada table_pk y validation_id, ordenada por execution_id ---\n",
    "        window_spec = Window.partitionBy(\"validation_id\", \"table_pk\").orderBy(\"execution_id\")\n",
    "\n",
    "        # --- 2. Calcular lag para la ejecución anterior ---\n",
    "        df_with_lag = df_evidences.alias(\"e\").join(\n",
    "            df_execution_pairs.select(\n",
    "                col(\"current_execution_id\"),\n",
    "                col(\"prev_execution_id\")\n",
    "            ).alias(\"p\"),\n",
    "            col(\"e.execution_id\") == col(\"p.current_execution_id\")\n",
    "        ).withColumn(\n",
    "            \"prev_execution_id_lag\", lag(\"execution_id\", 1).over(window_spec)\n",
    "        )\n",
    "\n",
    "        # --- 3. Clasificar cada fila como new, persistent o resolved ---\n",
    "        df_classified = df_with_lag.withColumn(\n",
    "            \"new_failure\", when(col(\"execution_id\") != col(\"prev_execution_id_lag\"), 1).otherwise(0)\n",
    "        ).withColumn(\n",
    "            \"persistent_failure\", when(col(\"execution_id\") == col(\"prev_execution_id_lag\"), 1).otherwise(0)\n",
    "        ).withColumn(\n",
    "            \"resolved_failure\", when(col(\"prev_execution_id_lag\").isNotNull() & (col(\"execution_id\") != col(\"prev_execution_id_lag\")), 1).otherwise(0)\n",
    "        )\n",
    "\n",
    "        # --- 4. Agregación final por ejecución y validación ---\n",
    "        df_metrics = df_classified.groupBy(\"execution_id\", \"validation_id\").agg(\n",
    "            count(\"new_failure\").alias(\"new_failures\"),\n",
    "            count(\"persistent_failure\").alias(\"persistent_failures\"),\n",
    "            count(\"resolved_failure\").alias(\"resolved_failures\")\n",
    "        )\n",
    "\n",
    "        # --- 5. Rellenar posibles nulls ---\n",
    "        df_metrics = df_metrics.fillna(0)\n",
    "\n",
    "        print(\"Cálculo de métricas finalizado (compacto, con ventanas).\")\n",
    "\n",
    "\n",
    "        # --- 5. Actualizar la tabla de trazabilidad (MERGE) ---\n",
    "        if not df_metrics.isEmpty():\n",
    "            print(f\"Actualizando (MERGE) registros en {VALIDATIONS_TABLE}...\")\n",
    "            \n",
    "            delta_validations_table = DeltaTable.forName(spark, VALIDATIONS_TABLE)\n",
    "\n",
    "            (delta_validations_table.alias(\"target\")\n",
    "             .merge(\n",
    "                 df_metrics.alias(\"source\"),\n",
    "                 (col(\"target.execution_id\") == col(\"source.execution_id\")) &\n",
    "                 (col(\"target.validation_id\") == col(\"source.validation_id\"))\n",
    "             )\n",
    "             .whenMatchedUpdate(set={\n",
    "                 \"persistent_failures\": \"source.persistent_failures\",\n",
    "                 \"new_failures\": \"source.new_failures\",\n",
    "                 \"resolved_failures\": \"source.resolved_failures\"\n",
    "             })\n",
    "             .execute()\n",
    "            )\n",
    "            print(\"Actualizaci��n de m��tricas de persistencia completada\")\n",
    "        else:\n",
    "            print(\"No se calcularon m��tricas, no hay nada que mergear.\")\n",
    "            \n",
    "        if 'df_evidences' in locals() and df_evidences.is_cached:\n",
    "            df_evidences.unpersist()\n",
    "\n",
    "\n",
    "        # --- 0. Reparticionar para merge eficiente ---\n",
    "        df_metrics = df_metrics.repartition(\"execution_id\", \"validation_id\")\n",
    "\n",
    "        # --- 1. Verificar si hay métricas para mergear ---\n",
    "        if not df_metrics.isEmpty():\n",
    "            print(\"Actualizando métricas en Delta...\")\n",
    "\n",
    "            delta_validations_table = DeltaTable.forName(spark, VALIDATIONS_TABLE)\n",
    "\n",
    "            # --- 2. Merge eficiente usando whenMatchedUpdateAll() ---\n",
    "            (delta_validations_table.alias(\"target\")\n",
    "                .merge(\n",
    "                    df_metrics.alias(\"source\"),\n",
    "                    (col(\"target.execution_id\") == col(\"source.execution_id\")) &\n",
    "                    (col(\"target.validation_id\") == col(\"source.validation_id\"))\n",
    "                )\n",
    "                .whenMatchedUpdateAll()  # Actualiza todas las columnas de df_metrics\n",
    "                .execute()\n",
    "            )\n",
    "\n",
    "            print(\"Actualización de métricas completada\")\n",
    "        else:\n",
    "            print(\"No se calcularon métricas, no hay nada que mergear.\")\n",
    "\n",
    "        # --- 3. Liberar memoria de df_evidences si estaba cacheado ---\n",
    "        if 'df_evidences' in locals() and df_evidences.is_cached:\n",
    "            df_evidences.unpersist()\n",
    "\n",
    "\n",
    "        # --- 6. Rellenar nulos en validaciones sin pares ---\n",
    "        print(f\"Limpiando nulos restantes en {VALIDATIONS_TABLE}...\")\n",
    "        \n",
    "        delta_validations_table = DeltaTable.forName(spark, VALIDATIONS_TABLE)\n",
    "        \n",
    "        zero_fill_values = {\n",
    "            \"persistent_failures\": 0,\n",
    "            \"new_failures\": 0,\n",
    "            \"resolved_failures\": 0\n",
    "        }\n",
    "        condition = (\n",
    "            col(\"status\").isin(\"PASSED\", \"FAILED\") & \n",
    "            (col(\"persistent_failures\").isNull() | col(\"new_failures\").isNull() | col(\"resolved_failures\").isNull())\n",
    "        )\n",
    "        \n",
    "        delta_validations_table.update(\n",
    "            condition = condition,\n",
    "            set = zero_fill_values\n",
    "        )\n",
    "        \n",
    "        print(\"Limpieza de nulos completada.\")\n",
    "        return \"C��lculo de persistencia finalizado.\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error fatal durante el c��lculo de persistencia: {e}\")\n",
    "        if 'df_evidences' in locals() and df_evidences.is_cached:\n",
    "            df_evidences.unpersist()\n",
    "        raise e\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# DBTITLE 3, 3. Punto de entrada de ejecuci��n\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        completion_message = main()\n",
    "        dbutils.notebook.exit(completion_message)\n",
    "    except Exception as e:\n",
    "        dbutils.notebook.exit(f\"Fallo en el c��lculo de persistencia: {e}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "04_calculate_persistence",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
